# Generated by Django 4.0.7 on 2022-09-30 20:30

import ast
from typing import Callable, Type

from django.db import migrations, transaction
from django.db.backends.base.schema import BaseDatabaseSchemaEditor
from django.db.migrations.state import StateApps
from django.db.models import JSONField, Model
from django.db.models.functions import Cast

# This migration is mostly the same as backfill_remote_realmauditlog_extradata_to_json_field in zerver

BATCH_SIZE = 5000


@transaction.atomic
def do_bulk_backfill_extra_data(
    audit_log_model: Type[Model], id_lower_bound: int, id_upper_bound: int
) -> None:
    # A dict converted with str() will start with a open bracket followed by a single quote,
    # as opposed to a JSON-encoded value, which will use a _double_ quote.
    # We use this to filter out those entries with malformed extra_data to be handled later.
    # This should only update rows with extra_data populated with orjson.dumps.
    (
        audit_log_model.objects.filter(
            extra_data__isnull=False, id__range=(id_lower_bound, id_upper_bound)
        )
        .exclude(extra_data__startswith="{'")
        .update(extra_data_json=Cast("extra_data", output_field=JSONField()))
    )

    python_valued_audit_log_entries = audit_log_model.objects.filter(
        extra_data__startswith="{'", id__range=(id_lower_bound, id_upper_bound)
    )
    for audit_log_entry in python_valued_audit_log_entries:
        # extra_data for entries that store dict stringified with builtins.str() are converted
        # back with ast.literal_eval for safety and efficiency.
        old_value = audit_log_entry.extra_data_json  # type: ignore[attr-defined] # The migration cannot depend on zerver.models, which contains the real type of the RealmAuditLog model, so it cannot be properly typed.
        new_value = ast.literal_eval(audit_log_entry.extra_data)  # type: ignore[attr-defined] # Explained above.
        audit_log_entry.extra_data_json = new_value  # type: ignore[attr-defined] # Explained above.
    audit_log_model.objects.bulk_update(python_valued_audit_log_entries, fields=["extra_data_json"])


def backfill_extra_data(model_name: str) -> Callable[[StateApps, BaseDatabaseSchemaEditor], None]:
    def inner(apps: StateApps, schema_editor: BaseDatabaseSchemaEditor) -> None:
        audit_log_model = apps.get_model("zilencer", model_name)
        if not audit_log_model.objects.filter(extra_data__isnull=False).exists():
            return

        audit_log_entries = audit_log_model.objects.filter(extra_data__isnull=False)
        id_lower_bound = audit_log_entries.earliest("id").id
        id_upper_bound = audit_log_entries.latest("id").id
        while id_lower_bound <= id_upper_bound:
            do_bulk_backfill_extra_data(
                audit_log_model, id_lower_bound, min(id_lower_bound + BATCH_SIZE, id_upper_bound)
            )
            id_lower_bound += BATCH_SIZE + 1

        do_bulk_backfill_extra_data(audit_log_model, id_lower_bound, id_upper_bound)

    return inner


class Migration(migrations.Migration):
    atomic = False

    dependencies = [
        ("zilencer", "0026_auditlog_models_extra_data_json"),
    ]

    operations = [
        migrations.RunPython(
            backfill_extra_data("RemoteRealmAuditLog"),
            reverse_code=migrations.RunPython.noop,
            elidable=True,
        ),
        migrations.RunPython(
            backfill_extra_data("RemoteZulipServerAuditLog"),
            reverse_code=migrations.RunPython.noop,
            elidable=True,
        ),
    ]
